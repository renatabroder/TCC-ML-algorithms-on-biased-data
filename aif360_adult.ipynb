{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aif360 - adult.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "5FnQeC0zkKRj",
        "ajR4htdTvbvw",
        "4EG4X_Jbvk_L",
        "E3ziyceUwXOC",
        "iaIeR8B2RvYd",
        "wYuylxlTxP1S",
        "4Clloh12wgYc",
        "PeMhXJ3LzuNI",
        "LHynRjRvH4Fl",
        "K98gKAm2tR2V"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suiSjCDDW-WG"
      },
      "source": [
        "# Análise de Desempenho em Algoritmos de Aprendizado de Máquina Treinados em Dados com Viés\n",
        "\n",
        "Renata Broder\n",
        "\n",
        "Lilian Berton"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeqPrp5oYhst"
      },
      "source": [
        "## Configurações iniciais\n",
        "\n",
        "Esta seção dedica-se à importação das bibliotecas necessárias para os experimentos que serão conduzidos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gys4VcqkiJvi"
      },
      "source": [
        "### Pip install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTlIELOzcqKz",
        "outputId": "77cd5000-70e6-47b2-8932-d80d084966b4"
      },
      "source": [
        "pip install aif360"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: aif360 in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from aif360) (1.1.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from aif360) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from aif360) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.6/dist-packages (from aif360) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from aif360) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->aif360) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->aif360) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->aif360) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->aif360) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->aif360) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21->aif360) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->aif360) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59r-1T17d85u",
        "outputId": "71977d7a-5aa3-4301-afeb-0568069bc966"
      },
      "source": [
        "pip install 'aif360[AdversarialDebiasing]'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: aif360[AdversarialDebiasing] in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from aif360[AdversarialDebiasing]) (1.1.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from aif360[AdversarialDebiasing]) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from aif360[AdversarialDebiasing]) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.6/dist-packages (from aif360[AdversarialDebiasing]) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from aif360[AdversarialDebiasing]) (1.19.5)\n",
            "Requirement already satisfied: tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\" in /usr/local/lib/python3.6/dist-packages (from aif360[AdversarialDebiasing]) (1.15.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->aif360[AdversarialDebiasing]) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->aif360[AdversarialDebiasing]) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->aif360[AdversarialDebiasing]) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->aif360[AdversarialDebiasing]) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->aif360[AdversarialDebiasing]) (0.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21->aif360[AdversarialDebiasing]) (1.0.0)\n",
            "Requirement already satisfied: h5py<=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (2.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (1.32.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (3.12.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (1.15.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (1.15.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (0.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (53.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (3.7.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FDeZXCIR5nc",
        "outputId": "050c5231-b130-40c7-a0df-324a0fdbad23"
      },
      "source": [
        "pip install 'aif360[LFR]'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: aif360[LFR] in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.6/dist-packages (from aif360[LFR]) (0.22.2.post1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from aif360[LFR]) (3.2.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from aif360[LFR]) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from aif360[LFR]) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from aif360[LFR]) (1.1.5)\n",
            "Requirement already satisfied: numba>=0.42.0; extra == \"lfr\" in /usr/local/lib/python3.6/dist-packages (from aif360[LFR]) (0.51.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21->aif360[LFR]) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->aif360[LFR]) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->aif360[LFR]) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->aif360[LFR]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->aif360[LFR]) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->aif360[LFR]) (2018.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.42.0; extra == \"lfr\"->aif360[LFR]) (53.0.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.42.0; extra == \"lfr\"->aif360[LFR]) (0.34.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->aif360[LFR]) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEtjF8iUVNRV",
        "outputId": "7033f682-9217-49a4-807d-c42ca4dcaf73"
      },
      "source": [
        "pip install BlackBoxAuditing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: BlackBoxAuditing in /usr/local/lib/python3.6/dist-packages (0.1.54)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from BlackBoxAuditing) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from BlackBoxAuditing) (3.2.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from BlackBoxAuditing) (2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from BlackBoxAuditing) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->BlackBoxAuditing) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->BlackBoxAuditing) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->BlackBoxAuditing) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->BlackBoxAuditing) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->BlackBoxAuditing) (2.4.7)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->BlackBoxAuditing) (4.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->BlackBoxAuditing) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw9kSK80iRw0"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVRlAsjDg-U6",
        "outputId": "fa07e7d2-59a2-480d-b65e-dd7c98434ab5"
      },
      "source": [
        "%matplotlib inline\n",
        "# Load all necessary packages\n",
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from aif360.datasets import BinaryLabelDataset, StandardDataset\n",
        "from aif360.datasets import AdultDataset #, GermanDataset, CompasDataset\n",
        "\n",
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "from aif360.metrics import ClassificationMetric\n",
        "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
        "\n",
        "from aif360.algorithms.preprocessing import Reweighing\n",
        "from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
        "\n",
        "# from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
        "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
        "            import load_preproc_data_adult\n",
        "# from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions\\\n",
        "#             import get_distortion_adult, get_distortion_german, get_distortion_compas\n",
        "# from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
        "\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:No module named 'numba.decorators': LFR will be unavailable. To install, run:\n",
            "pip install 'aif360[LFR]'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNIh1uuzt5Cj",
        "outputId": "96a7e1c9-6f20-4e97-a6dc-6ed196e9cad6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LDXfOBDY9g-"
      },
      "source": [
        "## Load do *Adult Dataset* e pré processamento inicial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dhI5qDGH7WA"
      },
      "source": [
        "Importar os arquivos do adult dataset do UCI para a pasta para a biblioteca aif360 poder realizar a leitura"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCJ9uZg_HJdQ",
        "outputId": "8f79b2ed-5630-41b7-ea87-9eef8a8c482a"
      },
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "open('/usr/local/lib/python3.6/dist-packages/aif360/data/raw/adult/adult.data', 'wb').write(r.content)\n",
        "\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "open('/usr/local/lib/python3.6/dist-packages/aif360/data/raw/adult/adult.test', 'wb').write(r.content)\n",
        "\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "open('/usr/local/lib/python3.6/dist-packages/aif360/data/raw/adult/adult.names', 'wb').write(r.content)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5229"
            ]
          },
          "execution_count": 7,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ti71feqQpWA"
      },
      "source": [
        "Por dentro da função load_preproc_data_adult:\n",
        "\n",
        "```python\n",
        "load_preproc_data_adult(['sex']):\n",
        "\n",
        "  XD_features = ['Age (decade)', 'Education Years', 'sex', 'race']\n",
        "  D_features = ['sex']\n",
        "  Y_features = ['Income Binary']\n",
        "  X_features = list(set(XD_features)-set(D_features))\n",
        "  categorical_features = ['Age (decade)', 'Education Years']\n",
        "\n",
        "  # privileged classes\n",
        "  all_privileged_classes = {\"sex\": [1.0],\n",
        "                              \"race\": [1.0]}\n",
        "  # protected attribute maps\n",
        "  all_protected_attribute_maps = {\"sex\": {1.0: 'Male', 0.0: 'Female'},\n",
        "\n",
        "  return AdultDataset(\n",
        "        label_name=Y_features[0],\n",
        "        favorable_classes=['>50K', '>50K.'],\n",
        "        protected_attribute_names=D_features,\n",
        "        privileged_classes=[all_privileged_classes[x] for x in D_features],\n",
        "        instance_weights_name=None,\n",
        "        categorical_features=categorical_features,\n",
        "        features_to_keep=X_features+Y_features+D_features,\n",
        "        na_values=['?'],\n",
        "        metadata={'label_maps': [{1.0: '>50K', 0.0: '<=50K'}],\n",
        "                  'protected_attribute_maps': [all_protected_attribute_maps[x]\n",
        "                                for x in D_features]},\n",
        "        custom_preprocessing=custom_preprocessing)\n",
        "                                    \"race\": {1.0: 'White', 0.0: 'Non-white'}}\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "O custom_preprocessing é o pré processamento de dados que é realizado especialmente para o **Adult Dataset**:\n",
        "\n",
        "```python\n",
        "# Group age by decade\n",
        "        df['Age (decade)'] = df['age'].apply(lambda x: x//10*10)\n",
        "\n",
        "        def group_edu(x):\n",
        "            if x <= 5: return '<6'\n",
        "            elif x >= 13: return '>12'\n",
        "            else: return x\n",
        "\n",
        "        def age_cut(x):\n",
        "            if x >= 70: return '>=70'\n",
        "            else: return x\n",
        "\n",
        "        def group_race(x):\n",
        "            if x == \"White\": return 1.0\n",
        "            else: return 0.0\n",
        "\n",
        "        # Cluster education and age attributes.\n",
        "        # Limit education range\n",
        "        df['Education Years'] = df['education-num'].apply(lambda x: group_edu(x))\n",
        "        df['Education Years'] = df['Education Years'].astype('category')\n",
        "\n",
        "        # Limit age range\n",
        "        df['Age (decade)'] = df['Age (decade)'].apply(lambda x: age_cut(x))\n",
        "\n",
        "        # Rename income variable\n",
        "        df['Income Binary'] = df['income-per-year']\n",
        "        df['Income Binary'] = df['Income Binary'].replace(to_replace='>50K.', value='>50K', regex=True)\n",
        "        df['Income Binary'] = df['Income Binary'].replace(to_replace='<=50K.', value='<=50K', regex=True)\n",
        "\n",
        "        # Recode sex and race\n",
        "        df['sex'] = df['sex'].replace({'Female': 0.0, 'Male': 1.0})\n",
        "        df['race'] = df['race'].apply(lambda x: group_race(x))\n",
        "\n",
        "```\n",
        "\n",
        "  Além deste pré processamento customizado que consiste no agrupamento dos atributos 'Education Years', 'Age', além do tratamento das categorias dos atributos já mencionados, bem como dos atributos 'Sex' e 'Race' (passo 1), também é realizado um pré processamento na classe **StandardDataset** a partir dos passos seguintes:\n",
        "2. Remoção de colunas não especificadas;\n",
        "3. Remoção de linhas que contém Na\n",
        "4. Tratamento para os dados categóricos\n",
        "5. Binarização dos labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_lbb3bOZ8ju"
      },
      "source": [
        "## Classe desfavorecida: **Gênero e Raça**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUqF-AMZQgYM"
      },
      "source": [
        "# Setar nome variável que seá utilizada no nome dos arquivos gerados\n",
        "name_unprivileged_groups = 'Gênero e Raça' #'Gênero e Raça'\n",
        "\n",
        "# Configurar gênero como classe desprivilegiada\n",
        "privileged_groups = [{'sex': 1, 'race': 1}]#, {'sex': 1, 'race': 1}]\n",
        "unprivileged_groups = [{'sex': 0, 'race': 0}]#, {'sex': 0, 'race': 0}]\n",
        "\n",
        "list_unprivileged_groups = ['sex', 'race'] #'sex', 'race']\n",
        "\n",
        "# Carregar o dataset já pré processado conforme processo descrito na seção anterior \n",
        "df_gender = load_preproc_data_adult(list_unprivileged_groups)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9CHZMAqBOBe"
      },
      "source": [
        "Agora a variável `df_gender` contém o dataset já pré processado. Vamos reutilizar este *dataset* para compor diferentes grupos de treino e teste gerados com diferentes *seeds* e medir a média da paridade demográfica "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGOIPgtABqI6",
        "outputId": "eb7e7c1f-848c-4fa9-92f8-eb6465169127"
      },
      "source": [
        "#random seed\n",
        "np.random.seed(13)\n",
        "\n",
        "# seeds = np.round((np.random.rand(30) * 1000))\n",
        "\n",
        "seeds = [ 36, 184, 892, 707, 826, 715, 777, 251, 740, 134, 676, 708, 839, 343,\n",
        " 393,  39, 937, 478, 325, 532, 161, 462, 660, 378, 872, 355, 636, 673,\n",
        " 447,  34]\n",
        "print(seeds)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[36, 184, 892, 707, 826, 715, 777, 251, 740, 134, 676, 708, 839, 343, 393, 39, 937, 478, 325, 532, 161, 462, 660, 378, 872, 355, 636, 673, 447, 34]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtNHmR2NiV7s"
      },
      "source": [
        "### Funções auxiliares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mi9HWHLmi3FP"
      },
      "source": [
        "#### Métricas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJswktklhVmf"
      },
      "source": [
        "from collections import OrderedDict\n",
        "from aif360.metrics import ClassificationMetric\n",
        "\n",
        "def compute_metrics(dataset_true, dataset_pred, \n",
        "                    unprivileged_groups, privileged_groups,\n",
        "                    best_class = -1,\n",
        "                    disp = False):\n",
        "    \"\"\" Compute the key metrics \"\"\"\n",
        "    m = ClassificationMetric(dataset_true,\n",
        "                             dataset_pred, \n",
        "                             unprivileged_groups=unprivileged_groups,\n",
        "                             privileged_groups=privileged_groups)\n",
        "    metrics = OrderedDict()\n",
        "    metrics[\"Accuracy\"] = m.accuracy()\n",
        "    metrics[\"Balanced accuracy\"] = 0.5*(m.true_positive_rate() + m.true_negative_rate())\n",
        "    metrics[\"Precision\"] = m.precision()\n",
        "    metrics[\"Recall\"] = m.recall()\n",
        "    metrics[\"F1-Score\"] = (2 * metrics[\"Precision\"] * metrics[\"Recall\"]) / (metrics[\"Precision\"] + metrics[\"Recall\"])\n",
        "    metrics[\"Statistical parity difference\"] = m.statistical_parity_difference()\n",
        "    metrics[\"Disparate impact\"] = m.disparate_impact()\n",
        "    metrics[\"Average odds difference\"] = m.average_odds_difference()\n",
        "    metrics[\"Equal opportunity difference\"] = m.equal_opportunity_difference()    \n",
        "    metrics[\"Class Threshold\"] = best_class\n",
        "    \n",
        "    if disp:\n",
        "        for k in metrics:\n",
        "            print(\"%s = %.4f\" % (k, metrics[k]))\n",
        "    \n",
        "    return metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpP14ke5gsHy"
      },
      "source": [
        "def avg_metrics_seeds(metricas, name):\n",
        "    # calculo das métricas para todos os testes\n",
        "    m_bal_acc = []\n",
        "    m_stat_par_diff = []\n",
        "    m_disp_imp = []\n",
        "    m_avg_odd_diff = []\n",
        "    m_eq_opp_diff = []\n",
        "    m_acc = []\n",
        "    m_prec = []\n",
        "    m_rec = []\n",
        "    m_f1 = []\n",
        "\n",
        "\n",
        "    df_metricas = pd.DataFrame.from_dict(metricas, orient='columns')\n",
        "\n",
        "    for i, s in enumerate(metricas):\n",
        "        m_acc.append(s['Accuracy'])\n",
        "        m_avg_odd_diff.append(s['Average odds difference'])\n",
        "        m_bal_acc.append(s['Balanced accuracy'])\n",
        "        m_disp_imp.append(s['Disparate impact'])\n",
        "        m_eq_opp_diff.append(s['Equal opportunity difference'])\n",
        "        m_f1.append(s['F1-Score'])\n",
        "        m_prec.append(s['Precision'])\n",
        "        m_rec.append(s['Recall'])\n",
        "        m_stat_par_diff.append(s['Statistical parity difference'])\n",
        "\n",
        "    df_mean = pd.DataFrame({\n",
        "        'Accuracy': round(np.mean(m_acc), 3),\n",
        "        'Balanced accuracy': round(np.mean(m_bal_acc), 3),\n",
        "        'Average odds difference': round(np.mean(m_avg_odd_diff), 3),\n",
        "        'Balanced accuracy': round(np.mean(m_bal_acc), 3),\n",
        "        'Disparate impact': round(np.mean(m_disp_imp), 3),\n",
        "        'Equal opportunity difference': round(np.mean(m_eq_opp_diff), 3),\n",
        "        'F1-Score': round(np.mean(m_f1), 3),\n",
        "        'Precision': round(np.mean(m_prec), 3),\n",
        "        'Recall': round(np.mean(m_rec), 3),\n",
        "        'Statistical parity difference': round(np.mean(m_stat_par_diff), 3),\n",
        "    }, index=['Media'])\n",
        "\n",
        "    #df_aux = [np.mean(m_bal_acc), np.mean(m_avg_odd_diff), np.mean(m_bal_acc)]\n",
        "\n",
        "    df_std = pd.DataFrame({\n",
        "        'Accuracy': round(np.std(m_acc), 3),\n",
        "        'Balanced accuracy': round(np.std(m_bal_acc), 3),\n",
        "        'Average odds difference': round(np.std(m_avg_odd_diff), 3),\n",
        "        'Balanced accuracy': round(np.std(m_bal_acc), 3),\n",
        "        'Disparate impact': round(np.std(m_disp_imp), 3),\n",
        "        'Equal opportunity difference': round(np.std(m_eq_opp_diff), 3),\n",
        "        'F1-Score': round(np.std(m_f1), 3),\n",
        "        'Precision': round(np.std(m_prec), 3),\n",
        "        'Recall': round(np.std(m_rec), 3),\n",
        "        'Statistical parity difference': round(np.std(m_stat_par_diff), 3),\n",
        "    }, index=['DesvPad'])\n",
        "\n",
        "    df_metricas = df_metricas.append(df_mean)\n",
        "    df_metricas = df_metricas.append(df_std)\n",
        "\n",
        "    df_metricas.to_csv(f'/content/drive/My Drive/UNIFESP/TCC/Arquivos - Adult/{name}.csv')\n",
        "\n",
        "    metricas = {\n",
        "        'ACC': np.mean(m_acc),\n",
        "        'AOD': np.mean(m_avg_odd_diff),\n",
        "        'BA': np.mean(m_bal_acc),\n",
        "        'DI': np.mean(m_disp_imp),\n",
        "        'EOD': np.mean(m_eq_opp_diff),\n",
        "        'F1': np.mean(m_f1),\n",
        "        'PRC': np.mean(m_prec),\n",
        "        'REC': np.mean(m_rec),\n",
        "        'SPD': np.mean(m_stat_par_diff),\n",
        "    }\n",
        "\n",
        "    display(Markdown(\"#### Acurácia (Objetivo: 1)\"))\n",
        "    print(metricas['ACC'])\n",
        "\n",
        "    display(Markdown(\"#### Acurácia Balanceada (Objetivo: 1)\"))\n",
        "    print(metricas['BA'])\n",
        "\n",
        "    display(Markdown(\"#### Diferença Paridade estatística (Objetivo: 0)\"))\n",
        "    print(metricas['SPD'])\n",
        "\n",
        "    display(Markdown(\"#### Impacto diferenciado (Objetivo: 1)\"))\n",
        "    print(metricas['DI'])\n",
        "\n",
        "    display(Markdown(\"#### F1 Score (Objetivo: 1)\"))\n",
        "    print(metricas['F1'])\n",
        "\n",
        "    display(Markdown(\"#### Recall (Objetivo: 1)\"))\n",
        "    print(metricas['REC'])\n",
        "\n",
        "    display(Markdown(\"#### Diferença de probabilidades (Objetivo: 0)\"))\n",
        "    print(metricas['AOD'])\n",
        "\n",
        "    display(Markdown(\"#### Equal opportunities difference (Objetivo: 0)\"))\n",
        "    print(metricas['EOD'])\n",
        "\n",
        "    return metricas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks7RmGrFO9Uq"
      },
      "source": [
        "def comparar_metricas(metricas, titulo, name):\n",
        "    def autolabel(rects):\n",
        "        \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "        for rect in rects:\n",
        "            height = rect.get_height()\n",
        "            ax.annotate('{}'.format(height),\n",
        "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                        xytext=(0, 3),  # 3 points vertical offset\n",
        "                        textcoords=\"offset points\",\n",
        "                        ha='center', va='bottom')\n",
        "\n",
        "\n",
        "    nome_metricas = ['Accuracy', 'Average Odds Difference', 'Balanced Accuracy', 'Disparate Impact', 'Equal Opportunities Difference', 'F1-Score', 'Precision', 'Recall', 'Statistical Parity Difference']\n",
        "    objetivo =      [         1,                         0,                   1,                  1,                                0,          1,           1,        1,                               0]\n",
        "    limites =       [  [0, 1.5],                   [-1, 1],            [0, 1.5],           [0, 1.5],                          [-1, 1],   [0, 1.5],    [0, 1.5], [0, 1.5],                         [-1, 1]]\n",
        "\n",
        "    for i, m in enumerate(metricas[0][0]):\n",
        "        #(i, m) = 0 BA, 1 SPD ...\n",
        "        x = np.arange(len(metricas))  # the label locations\n",
        "        width = 0.35  # the width of the bars\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(6, 5))\n",
        "        fig.patch.set_facecolor((1,1,1)) # color background\n",
        "\n",
        "        ax.set_title(name) # Título do gráfico\n",
        "        ax.set_xticks([]) # Definir que não tem ticks no eixo x\n",
        "        ax.axhline(objetivo[i], label='Goal', color='k', linestyle=':')\n",
        "\n",
        "        ax.set_xlabel(f'{nome_metricas[i]}')\n",
        "        plt.ylim(limites[i][0], limites[i][1])\n",
        "\n",
        "        for i, conjunto in enumerate(metricas):\n",
        "            aux = ax.bar(x[i], round(conjunto[0][m], 3), width, label=conjunto[1])\n",
        "            autolabel(aux)\n",
        "\n",
        "        ax.legend()\n",
        "        fig.tight_layout()\n",
        "        # plt.show()\n",
        "        fig.savefig(f'/content/drive/My Drive/UNIFESP/TCC/Gráficos - Adult/{name} - {titulo}_{m}.png') \n",
        "        plt.clf()\n",
        "\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OKn1ybTi6P0"
      },
      "source": [
        "#### Treino"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr6Upj0YJ2IT"
      },
      "source": [
        "def treino_valid_teste(df, clf, scaler, name, valid=True):\n",
        "    melhor_acur_bal = np.zeros(30)\n",
        "    melhor_lim_class = np.zeros(30)\n",
        "\n",
        "    metricas = []\n",
        "    metricas_seeds_sem_valid = []\n",
        "    metricas_seeds = []\n",
        "\n",
        "    for i, s in enumerate(seeds):\n",
        "        np.random.seed(s)\n",
        "\n",
        "        # Separação entre conjunto de teste, treino e validação\n",
        "        df_train, df_vt = df.split([0.7], shuffle=True)\n",
        "        df_valid, df_test = df_vt.split([0.5], shuffle=True)\n",
        "\n",
        "        x_train = scaler.fit_transform(df_train.features) # escalarização do dataset original para treino\n",
        "        y_train = df_train.labels.ravel() # label para o dataset de treino\n",
        "        w_train = df_train.instance_weights.ravel() # pesos iguais = 1\n",
        "\n",
        "\n",
        "\n",
        "        # Treino\n",
        "        clf.fit(x_train,\n",
        "                y_train,\n",
        "                sample_weight=w_train) # treino com todos os pesos iguais a 1\n",
        "\n",
        "        y_train_pred = clf.predict(x_train) # predição das mesmas entradas utilizadas para treino\n",
        "\n",
        "        df_train_pred = df_train.copy()  \n",
        "        df_train_pred.labels = y_train_pred # com os labels da predição feita com os dados de treino\n",
        "\n",
        "\n",
        "        pos_ind = np.where(clf.classes_ == df_train.favorable_label)[0][0] # pega índice da classe favoravel\n",
        "\n",
        "        # Validação\n",
        "        df_valid_pred = df_valid.copy(deepcopy=True) # cria cópia do conjunto de validação\n",
        "        x_valid = scaler.transform(df_valid_pred.features) # escalarização do conjunto\n",
        "        y_valid = df_valid_pred.labels # armazena labels na variável y_valid\n",
        "        df_valid_pred.scores = clf.predict_proba(x_valid)[:,pos_ind].reshape(-1,1) # guarda a probabilidade de a instância ser classificada como rotulo favorável (>50k)\n",
        "\n",
        "\n",
        "        # Classification threshold \"converte\" a probabilidade em classes binárias\n",
        "\n",
        "        # calcular acurácia balanceada e outras métricas para todos os limiares\n",
        "        num_thresh = 100\n",
        "        ba_arr = np.zeros(num_thresh)\n",
        "        class_thresh_arr = np.linspace(0.01, 0.99, num_thresh)\n",
        "\n",
        "        for idx, class_thresh in enumerate(class_thresh_arr):\n",
        "            \n",
        "            fav_inds = df_valid_pred.scores > class_thresh # Se a probabilidade de classificar a instancia de validação como favorita for maior do que o limiar de classe,\n",
        "            df_valid_pred.labels[fav_inds] = df_valid_pred.favorable_label # classifica como favorável\n",
        "            df_valid_pred.labels[~fav_inds] = df_valid_pred.unfavorable_label # se não, classifica como desfavorável\n",
        "            \n",
        "            metricas.append(ClassificationMetric(df_valid,       # dataset de validação original\n",
        "                                                df_valid_pred,  # labels gerados pela probabilidade do classificador\n",
        "                                                unprivileged_groups=unprivileged_groups,\n",
        "                                                privileged_groups=privileged_groups))\n",
        "            \n",
        "            ba_arr[idx] = 0.5*(metricas[-1].true_positive_rate()\\\n",
        "                            +metricas[-1].true_negative_rate()) # calcula a média entre as taxas de verdadeiros positivos e negativos armazenando para cada limiar de classe\n",
        "\n",
        "        best_ind = np.where(ba_arr == np.max(ba_arr))[0][0]\n",
        "        best_class_thresh = class_thresh_arr[best_ind]\n",
        "\n",
        "        melhor_acur_bal[i] = np.max(ba_arr)\n",
        "        melhor_lim_class[i] = np.max(best_class_thresh)\n",
        "\n",
        "\n",
        "        # Teste\n",
        "\n",
        "        df_test_pred = df_test.copy(deepcopy=True) # cria cópia do conjunto de teste\n",
        "        x_test = scaler.transform(df_test_pred.features) # escalarização do conjunto\n",
        "        y_test = df_test_pred.labels # armazena labels na variável y_test\n",
        "        df_test_pred.scores = clf.predict_proba(x_test)[:,pos_ind].reshape(-1,1) # guarda a probabilidade de a instância ser classificada como rotulo favorável (>50k)\n",
        "            \n",
        "        fav_inds = df_test_pred.scores > melhor_lim_class[i]\n",
        "        df_test_pred.labels[fav_inds] = df_test_pred.favorable_label\n",
        "        df_test_pred.labels[~fav_inds] = df_test_pred.unfavorable_label\n",
        "        \n",
        "        metric_test_bef = compute_metrics(df_test, df_test_pred, \n",
        "                                            unprivileged_groups, privileged_groups,\n",
        "                                            best_class_thresh)\n",
        "        metricas_seeds.append(metric_test_bef)\n",
        "\n",
        "\n",
        "\n",
        "        # Teste sem valid\n",
        "        df_test_pred.labels = clf.predict(x_test)\n",
        "        metric_test_sem_valid = compute_metrics(df_test, df_test_pred, \n",
        "                                                unprivileged_groups, privileged_groups)\n",
        "        metricas_seeds_sem_valid.append(metric_test_sem_valid)\n",
        "\n",
        "    metrica_df_gender = avg_metrics_seeds(metricas_seeds, name)\n",
        "    metrica_df_gender_sem_valid = avg_metrics_seeds(metricas_seeds_sem_valid, name + 'Sem validação')\n",
        "\n",
        "    return metrica_df_gender, metrica_df_gender_sem_valid, melhor_lim_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz9LzFMsNbKL"
      },
      "source": [
        "def treino_RW(df, clf, scaler, bct, name):\n",
        "    RW = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
        "\n",
        "    metricas_seeds_rw = []\n",
        "\n",
        "    for i, s in enumerate(seeds):\n",
        "        np.random.seed(s)\n",
        "\n",
        "        # Separação entre conjunto de teste, treino e validação\n",
        "        df_train, df_test = df.split([0.7], shuffle=True)\n",
        "        # df_valid, df_test = df_vt.split([0.5], shuffle=True)\n",
        "\n",
        "        # Rebalanceamento dos pesos\n",
        "        df_train_rw = RW.fit_transform(df_train) # aplicado o reweight no conjunto de treino\n",
        "\n",
        "        index = [df_train.feature_names.index(u) for u in list_unprivileged_groups]\n",
        "\n",
        "        df_train_rw.features = scaler.fit_transform(df_train_rw.features)\n",
        "        x_train_rw = df_train_rw.features#np.delete(df_train_rw.features, index, axis=1)\n",
        "        y_train_rw = df_train_rw.labels.ravel()\n",
        "        w_train_rw = df_train_rw.instance_weights\n",
        "\n",
        "        # x_valid_rw = scaler.fit_transform(df_valid.features)\n",
        "        #x_valid_rw = np.delete(x_valid_rw, index, axis=1)\n",
        "\n",
        "        x_test_rw = scaler.fit_transform(df_test.features)\n",
        "        #x_test_rw = np.delete(x_test_rw, index, axis=1)\n",
        "\n",
        "\n",
        "        clf.fit(x_train_rw,\n",
        "                y_train_rw, \n",
        "                sample_weight=w_train_rw) # treino com Regressão Logísitica e pesos do RW\n",
        "\n",
        "        y_train_pred = clf.predict(x_train_rw) # predição das mesmas entradas utilizadas para treino\n",
        "\n",
        "        pos_ind = np.where(clf.classes_ == df_train.favorable_label)[0][0] # pega índice da classe favoravel\n",
        "\n",
        "\n",
        "        # Validação\n",
        "        # df_valid_pred = df_valid.copy(deepcopy=True) # cria cópia do conjunto de validação\n",
        "        # df_valid_pred.scores = clf.predict_proba(x_valid_rw)[:,pos_ind].reshape(-1,1) # guarda a probabilidade de a instância ser classificada como rotulo favorável (>50k)\n",
        "\n",
        "\n",
        "        # Classification threshold \"converte\" a probabilidade em classes binárias\n",
        "\n",
        "        # calcular acurácia balanceada e outras métricas para todos os limiares\n",
        "        # num_thresh = 100\n",
        "        # ba_arr = np.zeros(num_thresh)\n",
        "        # class_thresh_arr = np.linspace(0.01, 0.99, num_thresh)\n",
        "        # metricas = []\n",
        "\n",
        "        # for idx, class_thresh in enumerate(class_thresh_arr):\n",
        "            \n",
        "        # fav_inds = df_valid_pred.scores > bct[i] # Se a probabilidade de classificar a instancia de validação como favorita for maior do que o limiar de classe,\n",
        "        # df_valid_pred.labels[fav_inds] = df_valid_pred.favorable_label # classifica como favorável\n",
        "        # df_valid_pred.labels[~fav_inds] = df_valid_pred.unfavorable_label # se não, classifica como desfavorável\n",
        "        \n",
        "        # metricas.append(ClassificationMetric(df_valid,       # dataset de validação original\n",
        "        #                                     df_valid_pred,  # labels gerados pela probabilidade do classificador\n",
        "        #                                     unprivileged_groups=unprivileged_groups,\n",
        "        #                                     privileged_groups=privileged_groups))\n",
        "        \n",
        "        # ba_arr[idx] = 0.5*(metricas[-1].true_positive_rate()\\\n",
        "                        # +metricas[-1].true_negative_rate()) # calcula a média entre as taxas de verdadeiros positivos e negativos armazenando para cada limiar de classe\n",
        "\n",
        "        # best_ind = np.where(ba_arr == np.max(ba_arr))[0][0]\n",
        "        # best_class_thresh = class_thresh_arr[best_ind]\n",
        "\n",
        "\n",
        "        # Teste\n",
        "        df_rw_test_pred = df_test.copy(deepcopy=True) # cria cópia do conjunto de teste\n",
        "        df_rw_test_pred.scores = clf.predict_proba(x_test_rw)[:,pos_ind].reshape(-1,1) # guarda a probabilidade de a instância ser classificada como rotulo favorável (>50k)\n",
        "                    \n",
        "        fav_inds = df_rw_test_pred.scores > bct[i]\n",
        "        df_rw_test_pred.labels[fav_inds] = df_rw_test_pred.favorable_label\n",
        "        df_rw_test_pred.labels[~fav_inds] = df_rw_test_pred.unfavorable_label\n",
        "        \n",
        "        metric_test_aft = compute_metrics(df_test, df_rw_test_pred, \n",
        "                                          unprivileged_groups, privileged_groups,\n",
        "                                          best_class=bct[i],\n",
        "                                          disp = False)\n",
        "        metricas_seeds_rw.append(metric_test_aft)\n",
        "\n",
        "    metrica_df_rw = avg_metrics_seeds(metricas_seeds_rw, name)\n",
        "\n",
        "    return metrica_df_rw\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEV6rVWiw4z9"
      },
      "source": [
        "def treino_DIR(df, clf, scaler, bct, name):\n",
        "    di = DisparateImpactRemover()\n",
        "\n",
        "    metric_df_di = []\n",
        "    for i, s in enumerate(seeds):\n",
        "        np.random.seed(s)\n",
        "        # Separação entre conjunto de teste, treino e validação\n",
        "        df_train, df_test = df.split([0.7], shuffle=True)\n",
        "        # df_valid, df_test = df_vt.split([0.5], shuffle=True)\n",
        "\n",
        "        df_train.features = scaler.fit_transform(df_train.features)\n",
        "        # df_valid.features = scaler.fit_transform(df_valid.features)\n",
        "        df_test.features = scaler.fit_transform(df_test.features)\n",
        "\n",
        "        index = [df_train.feature_names.index(u) for u in list_unprivileged_groups]\n",
        "\n",
        "        df_train_dir = di.fit_transform(df_train)\n",
        "        x_train_dir = np.delete(df_train_dir.features, index, axis=1)\n",
        "        y_train_dir = df_train_dir.labels.ravel()\n",
        "        \n",
        "        # df_valid_dir = di.fit_transform(df_valid)\n",
        "        # x_valid_dir = np.delete(df_valid_dir.features, index, axis=1)\n",
        "\n",
        "        df_test_dir = di.fit_transform(df_test)\n",
        "        x_test_dir = np.delete(df_test_dir.features, index, axis=1)\n",
        "        \n",
        "        clf.fit(x_train_dir, y_train_dir)\n",
        "\n",
        "        pos_ind = np.where(clf.classes_ == df_test.favorable_label)[0][0] # pega índice da classe favoravel\n",
        "\n",
        "        # # Validação\n",
        "        # df_valid_pred = df_valid_dir.copy(deepcopy=True) # cria cópia do conjunto de validação\n",
        "        # x_valid = scaler.transform(df_valid_pred.features) # escalarização do conjunto\n",
        "        # y_valid = df_valid_pred.labels # armazena labels na variável y_valid\n",
        "        # df_valid_pred.scores = clf.predict_proba(x_valid_dir)[:,pos_ind].reshape(-1,1) # guarda a probabilidade de a instância ser classificada como rotulo favorável (>50k)\n",
        "\n",
        "\n",
        "        # Classification threshold \"converte\" a probabilidade em classes binárias\n",
        "\n",
        "        # # calcular acurácia balanceada e outras métricas para todos os limiares\n",
        "        # num_thresh = 100\n",
        "        # ba_arr = np.zeros(num_thresh)\n",
        "        # class_thresh_arr = np.linspace(0.01, 0.99, num_thresh)\n",
        "        # metricas = []\n",
        "\n",
        "        # for idx, class_thresh in enumerate(class_thresh_arr):\n",
        "            \n",
        "        #     fav_inds = df_valid_pred.scores > class_thresh # Se a probabilidade de classificar a instancia de validação como favorita for maior do que o limiar de classe,\n",
        "        #     df_valid_pred.labels[fav_inds] = df_valid_pred.favorable_label # classifica como favorável\n",
        "        #     df_valid_pred.labels[~fav_inds] = df_valid_pred.unfavorable_label # se não, classifica como desfavorável\n",
        "            \n",
        "        #     metricas.append(ClassificationMetric(df_valid,       # dataset de validação original\n",
        "        #                                         df_valid_pred,  # labels gerados pela probabilidade do classificador\n",
        "        #                                         unprivileged_groups=unprivileged_groups,\n",
        "        #                                         privileged_groups=privileged_groups))\n",
        "            \n",
        "        #     ba_arr[idx] = 0.5*(metricas[-1].true_positive_rate()\\\n",
        "        #                     +metricas[-1].true_negative_rate()) # calcula a média entre as taxas de verdadeiros positivos e negativos armazenando para cada limiar de classe\n",
        "\n",
        "        # best_ind = np.where(ba_arr == np.max(ba_arr))[0][0]\n",
        "        # best_class_thresh = class_thresh_arr[best_ind]\n",
        "\n",
        "\n",
        "        # Treino\n",
        "\n",
        "        df_test_pred = df_test.copy(deepcopy=True)\n",
        "        df_test_pred.scores = clf.predict_proba(x_test_dir)[:,pos_ind].reshape(-1,1) # guarda a probabilidade de a instância ser classificada como rotulo favorável (>50k)\n",
        "\n",
        "        fav_inds = df_test_pred.scores > bct[i]\n",
        "        df_test_pred.labels[fav_inds] = df_test_pred.favorable_label\n",
        "        df_test_pred.labels[~fav_inds] = df_test_pred.unfavorable_label\n",
        "\n",
        "        ##\n",
        "\n",
        "        metric_test_aft = compute_metrics(df_test, df_test_pred, \n",
        "                                            unprivileged_groups, privileged_groups,\n",
        "                                            best_class=bct[i],\n",
        "                                            disp = False)\n",
        "                \n",
        "        # Métrica (conjunto de treino): Statistical Parity Difference\n",
        "        metric_df_di.append(metric_test_aft)\n",
        "    \n",
        "    metrica_df_dir = avg_metrics_seeds(metric_df_di, name)\n",
        "\n",
        "    return metrica_df_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFXWYd31al6y"
      },
      "source": [
        "## Técnicas de pré processamento para mitigação de viés"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FnQeC0zkKRj"
      },
      "source": [
        "#### **Paridade demográfica (*Statistical Parity Difference - SPD*)**\n",
        "\n",
        "A distribuição da probabilidade de predição positiva (ou negativa) deve ser idêntica nas subpopulações privilegiadas e desprivilegiadas:\n",
        "\n",
        "$$ SPD = 𝑃𝑟(𝑌=1|𝐷=unprivileged)−𝑃𝑟(𝑌=1|𝐷=privileged) $$\n",
        "\n",
        "SPD é \"mais justo\" quanto mais próximo de 0!\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGVBnda_BLH_",
        "outputId": "6b21e5cb-f2c8-4f21-86ff-639614995130"
      },
      "source": [
        "metric_df_gender_spd = []\n",
        "\n",
        "for s in seeds:\n",
        "    np.random.seed(s)\n",
        "    # Separação entre conjunto de teste, treino e validação\n",
        "    df_gender_train, df_gender_vt = df_gender.split([0.7], shuffle=True)\n",
        "    #df_gender_valid, df_gender_test = df_gender_vt.split([0.5], shuffle=True)\n",
        "\n",
        "    # Métrica (conjunto de treino): Statistical Parity Difference\n",
        "    metric_df_gender_spd.append(BinaryLabelDatasetMetric(df_gender_train, \n",
        "                                                         unprivileged_groups=unprivileged_groups,\n",
        "                                                         privileged_groups=privileged_groups)\n",
        "                                                        .mean_difference())\n",
        "\n",
        "\n",
        "display(Markdown(\"#### SPD - Adult Dataset Original (grupo discriminado: gênero)\"))\n",
        "print(\"Média da diferença nos resultados médios entre grupos não privilegiados e privilegiados = %f\" % np.mean(metric_df_gender_spd))\n",
        "print(\"Desvio padrão da diferença nos resultados médios entre grupos não privilegiados e privilegiados = %f\" % np.std(metric_df_gender_spd))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/markdown": "#### SPD - Adult Dataset Original (grupo discriminado: gênero)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Média da diferença nos resultados médios entre grupos não privilegiados e privilegiados = -0.243302\n",
            "Desvio padrão da diferença nos resultados médios entre grupos não privilegiados e privilegiados = 0.003876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9namxuttAarT",
        "outputId": "dab2bb1b-1520-4a12-a79f-22796bafbed8"
      },
      "source": [
        "metric_df_gender_spd_rw = []\n",
        "RW = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
        "\n",
        "for s in seeds:\n",
        "  np.random.seed(s)\n",
        "  # Separação entre conjunto de teste, treino e validação\n",
        "  df_gender_train, df_gender_vt = df_gender.split([0.7], shuffle=True)\n",
        "  #df_gender_valid, df_gender_test = df_gender_vt.split([0.5], shuffle=True)\n",
        "  \n",
        "  df_gender_rw_train = RW.fit_transform(df_gender_train) # aplicado o reweight no conjunto de treino\n",
        "\n",
        "  metric_df_gender_spd_rw.append(BinaryLabelDatasetMetric(df_gender_rw_train, \n",
        "                                                          unprivileged_groups=unprivileged_groups,\n",
        "                                                          privileged_groups=privileged_groups)\n",
        "                                                          .mean_difference())\n",
        "  \n",
        "display(Markdown(\"#### SPD - Adult Dataset Rebalanceado (grupo discriminado: gênero)\"))\n",
        "print(\"Média da diferença nos resultados médios entre grupos não privilegiados e privilegiados = %f\" % np.mean(metric_df_gender_spd_rw))\n",
        "print(\"Desvio padrão da diferença nos resultados médios entre grupos não privilegiados e privilegiados = %f\" % np.std(metric_df_gender_spd_rw))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/markdown": "#### SPD - Adult Dataset Rebalanceado (grupo discriminado: gênero)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Média da diferença nos resultados médios entre grupos não privilegiados e privilegiados = -0.000000\n",
            "Desvio padrão da diferença nos resultados médios entre grupos não privilegiados e privilegiados = 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Inz2hmkd_9P"
      },
      "source": [
        "#### Regressão Logística"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wlNweTAUyvR"
      },
      "source": [
        "##### Dataset original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "id": "7RCwnjaChUqa",
        "outputId": "9ce8e710-2a3d-41a2-a5da-27e86f62902c"
      },
      "source": [
        "scale_orig = StandardScaler()\n",
        "lmod = LogisticRegression(class_weight='balanced', solver='liblinear')\n",
        "\n",
        "metrica_RL, metrica_RL_sem_valid, threshold_RL = treino_valid_teste(df_gender, lmod, scale_orig, f'{name_unprivileged_groups} - RL - Original')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7374368773031253\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7441653519690381\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.4738569150203708\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.11615933177350404\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5801668338031563\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7570682012406624\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.44792139553810345\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.5392620954109174\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7304626723079023\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7445061612750578\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.48525905194109686\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.12209351670277703\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5783586803047146\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7714717458211591\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.44993134947527014\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.5287196726967659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSLpbhXm-nDR"
      },
      "source": [
        "##### Dataset Reweighing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "FL-D2ChL-S5D",
        "outputId": "a0ec3252-07d7-4a48-addc-d692b19b3ba1"
      },
      "source": [
        "scale_transf = StandardScaler()\n",
        "lmod = LogisticRegression(class_weight='balanced', solver='liblinear')\n",
        "\n",
        "metrica_RL_RW = treino_RW(df_gender, lmod, scale_transf, threshold_RL, f'{name_unprivileged_groups} - RL - Reweighing')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7622420892194999\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7223208893518213\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.19422098520159556\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.4719822011685101\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5651916701326468\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6457032215272496\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.09289926415482573\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.09695784624577719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0Q8g6a3dAT8"
      },
      "source": [
        "##### Dataset Disparate Impact Remover"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "p8Pp0kr4Sy0F",
        "outputId": "124a7bc2-7cda-48f8-ff74-9f6897461e64"
      },
      "source": [
        "scaler_orig = MinMaxScaler() #MinMaxScaler()StandardScaler()\n",
        "lmod = LogisticRegression(class_weight='balanced', solver='liblinear')\n",
        "\n",
        "metrica_RL_DIR = treino_DIR(df_gender, lmod, scaler_orig, threshold_RL, f'{name_unprivileged_groups} - RL - Disparate Impact Remover')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7232375622739372\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.713940190093824\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.10784584796163009\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7280044776216053\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.546620698893466\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6961062627820505\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.0070329827784765975\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.012825152449152544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajR4htdTvbvw"
      },
      "source": [
        "##### Comparativo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ydt5nlWmkeK6"
      },
      "source": [
        "comparar_metricas([[metrica_RL, 'Original'],\n",
        "                   [metrica_RL_RW, 'Reweighing'],\n",
        "                   [metrica_RL_DIR, 'Disparate Impact Remover']],\n",
        "                  'Regressão Logística', f'{name_unprivileged_groups} - RL')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNnGS2PWEQjt"
      },
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he9zF_uXEQkQ"
      },
      "source": [
        "##### Dataset original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "id": "qvzF-9ypEQkR",
        "outputId": "86036fe0-a82e-4dc8-9387-ce1d7d3c0af3"
      },
      "source": [
        "scale_orig = StandardScaler()\n",
        "RF = RandomForestClassifier()\n",
        "\n",
        "metrica_RF, metrica_RF_sem_valid, threshold_RF = treino_valid_teste(df_gender, RF, scale_orig, f'{name_unprivileged_groups} - RF - Original')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7341294754560758\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7436358221415863\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.45454502659258367\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.1577194365956212\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5786907712758027\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7619178554098347\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.40494082091277195\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.4684070220573227\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.802938901778809\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6628722727312881\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.23284881515817535\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0003052448800249387\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.489088507583159\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.3938562458006987\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.29845886524034526\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.4766578506925923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJN5kcE0Eaaf"
      },
      "source": [
        "##### Dataset Reweighing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "LkRzGwN0EQkV",
        "outputId": "d48050d4-1baf-4216-c25e-46f500fc5b24"
      },
      "source": [
        "scale_transf = StandardScaler()\n",
        "RW = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
        "RF = RandomForestClassifier()\n",
        "\n",
        "metrica_RF_RW = treino_RW(df_gender, RF, scale_transf, threshold_RF, f'{name_unprivileged_groups} - RF - Reweighing')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7583179781159719\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7263412163267197\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.16131061496859672\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5943911782151066\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5687313018885038\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6651260450176787\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.08171862877665619\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.11276241638789025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPw1q4LBwwyu"
      },
      "source": [
        "##### Dataset Disparate Impact Remover"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "X8HOnmAtwwzQ",
        "outputId": "70ce138f-791d-49e2-c322-dbad7d24fd4c"
      },
      "source": [
        "scaler_orig = MinMaxScaler()\n",
        "RF = RandomForestClassifier()\n",
        "\n",
        "metrica_RF_DIR = treino_DIR(df_gender, RF, scaler_orig, threshold_RF, f'{name_unprivileged_groups} - RF - Disparate Impact Remover')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7177574558110965\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.713462981683551\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.10417746419486021\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7377882305881944\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5455195110410579\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7054852430021936\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.008404511089933913\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.020269362353599867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EG4X_Jbvk_L"
      },
      "source": [
        "##### Comparativo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nDBN0sOEQkW"
      },
      "source": [
        "comparar_metricas([[metrica_RF, 'Original'],\n",
        "                   [metrica_RF_RW, 'Reweighing'],\n",
        "                   [metrica_RF_DIR, 'Disparate Impact Remover']],\n",
        "                  'Random Forest', f'{name_unprivileged_groups} - RF')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTLxm1kYHPXB"
      },
      "source": [
        "#### Nayve Bayes Bernoulli"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUvgRwYOHPXK"
      },
      "source": [
        "##### Dataset original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "id": "P1hCIEBNHPXN",
        "outputId": "f8c9b24f-9cda-430f-f1fb-0e30e16936aa"
      },
      "source": [
        "scale_orig = StandardScaler()\n",
        "NB = BernoulliNB()\n",
        "\n",
        "metrica_NB, metrica_NB_sem_valid, threshold_NB = treino_valid_teste(df_gender, NB, scale_orig, f'{name_unprivileged_groups} - NB - Original')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7384604886037943\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7431045351718037\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.4032454143459806\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.2342333637015064\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5794678338544728\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7520276955121593\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.3062659737495211\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.3146227896985633\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7957599745234522\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6792362613160774\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.24819477383149346\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5165362399319962\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.4554536951104361\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.3155898562408638\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.4986855515943771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5GE8Z20HPXP"
      },
      "source": [
        "##### Dataset Reweighing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "_-IUx4UkHPXQ",
        "outputId": "0f3267f0-8cbd-42cc-f1d1-008ec764aa72"
      },
      "source": [
        "scale_transf = StandardScaler()\n",
        "NB = BernoulliNB()\n",
        "\n",
        "metrica_NB_RW = treino_RW(df_gender, NB, scale_transf, threshold_NB, f'{name_unprivileged_groups} - NB - Reweighing')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7655747400987284\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7176554308523688\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.20180109739670168\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.42426880357001767\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5610691674141673\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6257002727454263\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.10170795093288564\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.10552862917371625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxpESWjrxGjj"
      },
      "source": [
        "##### Dataset Disparate Impact Remover"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "-Z07G4UGxGkA",
        "outputId": "5944ddb3-d449-4963-c810-ec80f0527250"
      },
      "source": [
        "scaler_orig = MinMaxScaler()\n",
        "NB = BernoulliNB()\n",
        "\n",
        "metrica_NB_DIR = treino_DIR(df_gender, NB, scaler_orig, threshold_NB, f'{name_unprivileged_groups} - NB - Disparate Impact Remover')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7354261925885484\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7102662141235502\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.09621177768065182\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7394165872882196\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5452586832003193\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6620067467877947\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.014643867995042545\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.02337280857062961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3ziyceUwXOC"
      },
      "source": [
        "##### Comparativo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w4HERCoHPXR",
        "outputId": "401a5beb-411b-46a0-cc0d-e697b3ea4c08"
      },
      "source": [
        "comparar_metricas([[metrica_NB, 'Original'],\n",
        "                   [metrica_NB_RW, 'Reweighing'],\n",
        "                   [metrica_NB_DIR, 'Disparate Impact Remover']],\n",
        "                  'Naive Bayes', f'{name_unprivileged_groups} - NB')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ni-iVfpRvYQ"
      },
      "source": [
        "#### Árvore de decisão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WDmJM2JRvYb"
      },
      "source": [
        "##### Dataset original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "id": "dKOcD_SFRvYc",
        "outputId": "3664e350-f07a-4597-d487-eaf2498bd96f"
      },
      "source": [
        "scale_orig = StandardScaler()\n",
        "DT = DecisionTreeClassifier()\n",
        "\n",
        "metrica_DT, metrica_DT_sem_valid, threshold_DT = treino_valid_teste(df_gender, DT, scale_orig, f'{name_unprivileged_groups} - AD - Original')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.734193166825895\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7435872440644343\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.45222912797182957\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.16347806521616365\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5786823954891894\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7616502318831498\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.4009242932664948\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.46229304385320824\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8030753832855648\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6623167563629766\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.23130852315638037\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.4880719167582878\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.39197384253459056\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.29670596921210646\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.47438018424410344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaIeR8B2RvYd"
      },
      "source": [
        "##### Dataset  Reweighing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gck41CHWRvYe",
        "outputId": "6de9dff2-f0b2-40ee-f684-fa1cb31c45f7"
      },
      "source": [
        "scale_transf = StandardScaler()\n",
        "DT = DecisionTreeClassifier()\n",
        "\n",
        "metrica_DT_RW = treino_RW(df_gender, DT, scale_transf, threshold_DT, f'{name_unprivileged_groups} - AD - Reweighing')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.757888032029846\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7256521488543338\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.15448380383374635\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6122929062921075\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5678670086154863\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.664045708235637\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.07303356187417588\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.10140955408595254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYuylxlTxP1S"
      },
      "source": [
        "##### Dataset Disparate Impact Remover"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXU1hXhgxP1T",
        "outputId": "44188da9-c735-484c-c0d6-0c4b2ddd8c29"
      },
      "source": [
        "scaler_orig = MinMaxScaler()\n",
        "DT = DecisionTreeClassifier()\n",
        "\n",
        "metrica_DT_DIR = treino_DIR(df_gender, DT, scaler_orig, threshold_DT, f'{name_unprivileged_groups} - AD - Disparate Impact Remover')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7182692963898176\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7129072142895654\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.1044088176643401\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7356131091709204\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5450955433429212\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7029405503012275\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.008352862350405511\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.019453776748766416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Clloh12wgYc"
      },
      "source": [
        "##### Comparativo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p7dprjpRvYe",
        "outputId": "f88c50a7-460f-41f9-8701-b9362fc47bb1"
      },
      "source": [
        "comparar_metricas([[metrica_DT, 'Original'],\n",
        "                   [metrica_DT_RW, 'Reweighing'],\n",
        "                   [metrica_DT_DIR,'Disparate Impact Remover']],\n",
        "                  'Árvore de decisão', f'{name_unprivileged_groups} - AD')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw122ZXFzuNC"
      },
      "source": [
        "#### SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-H9uU2KzuNG"
      },
      "source": [
        "##### Dataset original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "id": "_a0liKydzuNG",
        "outputId": "73ded81a-dddf-48dc-af18-93c4c09b1804"
      },
      "source": [
        "scale_orig = StandardScaler()\n",
        "LinearSVM = LinearSVC(dual=False)\n",
        "SVM = CalibratedClassifierCV(LinearSVM)\n",
        "\n",
        "metrica_SVM, metrica_SVM_sem_valid, threshold_SVM = treino_valid_teste(df_gender, SVM, scale_orig, f'{name_unprivileged_groups} - SVM - Original')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7281879805286383\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7405890052101921\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.47634085677698945\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.1412206494244976\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5742500332941737\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7645595962405609\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.4280563919413515\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.48843087750180575\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8034575315044811\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6615070832425946\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.22682823807920302\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.4866296549696595\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.3888782352033942\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.2918050266403925\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.46834130409576147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M-tk_P3wVL5"
      },
      "source": [
        "##### Dataset Reweighing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "wVy9xvucwVMq",
        "outputId": "02d7d378-a4b7-484f-d24b-57daefdfe1bd"
      },
      "source": [
        "scale_transf = StandardScaler()\n",
        "LinearSVM = LinearSVC(dual=False)\n",
        "SVM = CalibratedClassifierCV(LinearSVM)\n",
        "\n",
        "metrica_SVM_RW = treino_RW(df_gender, SVM, scale_transf, threshold_SVM, f'{name_unprivileged_groups} - SVM - Reweighing')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7627744034213698\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7183640538441725\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.19601154109353222\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.4552342136828592\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5609458473803054\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.633182914349808\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.09604138746285527\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.09965830166504593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlQVzCRzzuNI"
      },
      "source": [
        "##### Dataset transformado pelo Disparate Impact Remover"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "fbj6RN_OzuNI",
        "outputId": "21d87145-eaae-4d46-bc10-bfcd6d06e56d"
      },
      "source": [
        "scaler_orig = MinMaxScaler()\n",
        "LinearSVM = LinearSVC(dual=False)\n",
        "SVM = CalibratedClassifierCV(LinearSVM)\n",
        "\n",
        "metrica_SVM_DIR = treino_DIR(df_gender, SVM, scaler_orig, threshold_SVM, f'{name_unprivileged_groups} - SVM - Disparate Impact Remover')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7340567346845924\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7104581551758941\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.1066489463586183\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7081025625667042\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5458237032100164\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6652605708238444\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.004045845193772703\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.005964705841760057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeMhXJ3LzuNI"
      },
      "source": [
        "##### Comparativo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVaV7CagzuNJ",
        "outputId": "06ebdd83-1a3b-4a64-f03d-0ac66de0a6b7"
      },
      "source": [
        "comparar_metricas([[metrica_SVM, 'Original'],\n",
        "                   [metrica_SVM_RW, 'Reweighing'],\n",
        "                   [metrica_SVM_DIR, 'Disparate Impact Remover']],\n",
        "                  'SVM', f'{name_unprivileged_groups} - SVM') #[metrica_SVM_DIR,'Disparate Impact Remover']], 'SVM')\n",
        "                  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQnH2uLRH4FS"
      },
      "source": [
        "#### MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRmVV0n6H4Fd"
      },
      "source": [
        "##### Dataset original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tF6tW7qfH4Fe",
        "outputId": "c47450a7-bb70-436e-f7e2-e609f3e9cb0a"
      },
      "source": [
        "scale_orig = StandardScaler()\n",
        "MLP_cl = MLPClassifier()\n",
        "MLP = CalibratedClassifierCV(MLP_cl)\n",
        "\n",
        "metrica_MLP, metrica_MLP_sem_valid, threshold_MLP = treino_valid_teste(df_gender, MLP, scale_orig, f'{name_unprivileged_groups} - MLP - Original')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7336927346344572\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.743847964839656\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.46651266672640684\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.14339329877724086\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.578813699783085\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7633962381180006\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.4260991801732958\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.49966334644571686\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8031845684909694\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6620694272184529\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.23098678104125445\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.4875777393951033\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.39104346937677464\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.29633278737004976\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.4738638607212807\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRQ3UjUfuHEx"
      },
      "source": [
        "##### Dataset Reweighing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWHkUR9tuHFW",
        "outputId": "ef54f708-3cdd-4e91-d10b-843c7ea733e2"
      },
      "source": [
        "scale_transf = StandardScaler()\n",
        "MLP_cl = MLPClassifier()\n",
        "MLP = CalibratedClassifierCV(MLP_cl)\n",
        "\n",
        "metrica_MLP_RW = treino_RW(df_gender, MLP, scale_transf, threshold_MLP, f'{name_unprivileged_groups} - MLP - Reweighing')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:175: UserWarning: MLPClassifier does not support sample_weight. Samples weights are only used for the calibration itself.\n",
            "  \" itself.\" % estimator_name)\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7513410223162492\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7393216385309832\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.42542990999599384\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.120656183094511\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5796982435904313\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7163345389717957\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.41262533780270066\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.5208193089604618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR_1v2-wH4Fi"
      },
      "source": [
        "##### Dataset transformado pelo Disparate Impact Remover"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YN5qRUzQH4Fj",
        "outputId": "ff61e91b-a0e1-4f05-8ab8-525938bc1d32"
      },
      "source": [
        "scaler_orig = MinMaxScaler()\n",
        "MLP_cl = MLPClassifier()\n",
        "MLP = CalibratedClassifierCV(MLP_cl)\n",
        "\n",
        "metrica_MLP_DIR = treino_DIR(df_gender, MLP, scaler_orig, threshold_MLP, f'{name_unprivileged_groups} - MLP - Disparate Impact Remover')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/markdown": "#### Acurácia (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7112809663550125\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Acurácia Balanceada (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.713215789384505\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença Paridade estatística (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.10175164829181124\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Impacto diferenciado (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7498217546832826\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### F1 Score (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5438785850107796\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Recall (Objetivo: 1)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7170199153509146\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Diferença de probabilidades (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.004821580002863747\n"
          ]
        },
        {
          "data": {
            "text/markdown": "#### Equal opportunities difference (Objetivo: 0)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.015070781461616537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHynRjRvH4Fl"
      },
      "source": [
        "##### Comparativo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9aPrIr0nH4Fm",
        "outputId": "575c7698-bfb9-46d9-b794-ea9acd7ff4f3"
      },
      "source": [
        "comparar_metricas([[metrica_MLP, 'Original'],\n",
        "                   [metrica_MLP_RW, 'Reweighing'],\n",
        "                   [metrica_MLP_DIR,'Disparate Impact Remover']],\n",
        "                  'MLP', f'{name_unprivileged_groups} - MLP')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu8TSPJ8OGK8"
      },
      "source": [
        "### Comparativo entre todos os algoritmos rodando no dataset original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "86NkMvXKOMd_",
        "outputId": "ea898e60-2b9a-46ce-fba2-f289491a17d8"
      },
      "source": [
        "comparar_metricas([[metrica_RL, 'Regressão Logística'],\n",
        "                   [metrica_RF, 'Random Forest'],\n",
        "                   [metrica_NB, 'Nayve Bayes'],\n",
        "                   [metrica_DT, 'Árvore de Decisão'],\n",
        "                   [metrica_SVM, 'SVM'],\n",
        "                   [metrica_MLP, 'MLP']],\n",
        "                   'Algoritmos', f'{name_unprivileged_groups} - Sem debiasing')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh-GJZxqRR0J"
      },
      "source": [
        "### Comparativo entre todos os algoritmos rodando no dataset original - Sem validação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0QNSeT58RR0J",
        "outputId": "f1ad4ca0-2481-409a-a091-2b700ce53bbf"
      },
      "source": [
        "comparar_metricas([[metrica_RL_sem_valid, 'Regressão Logística'],\n",
        "                   [metrica_RF_sem_valid, 'Random Forest'],\n",
        "                   [metrica_NB_sem_valid, 'Nayve Bayes'],\n",
        "                   [metrica_DT_sem_valid, 'Árvore de Decisão'],\n",
        "                   [metrica_SVM_sem_valid, 'SVM'],\n",
        "                   [metrica_MLP_sem_valid, 'MLP']],\n",
        "                   'Algoritmos', f'{name_unprivileged_groups} - Sem debiasing - Sem Validação')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K98gKAm2tR2V"
      },
      "source": [
        "### Comparativo entre todos os algoritmos utilizando Reweighing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AGYplSLStZw4",
        "outputId": "13bec525-7dea-4392-ae8e-8f8e8f8bef28"
      },
      "source": [
        "comparar_metricas([[metrica_RL_RW, 'Regressão Logística'],\n",
        "                   [metrica_RF_RW, 'Random Forest'],\n",
        "                   [metrica_NB_RW, 'Nayve Bayes'],\n",
        "                   [metrica_DT_RW, 'Árvore de Decisão'],\n",
        "                   [metrica_SVM_RW, 'SVM'],\n",
        "                   [metrica_MLP_RW, 'MLP']],\n",
        "                   'Algoritmos', f'{name_unprivileged_groups} - Reweighing')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yf5AYMZqtwGm"
      },
      "source": [
        "### Comparativo entre todos os algoritmos utilizando Disparate Impact Remover"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Rfhr-gOSt1rB",
        "outputId": "7c2565e4-28c7-4b6e-a9a6-9845cccad43f"
      },
      "source": [
        "comparar_metricas([[metrica_RL_DIR, 'Regressão Logística'],\n",
        "                   [metrica_RF_DIR, 'Random Forest'],\n",
        "                   [metrica_NB_DIR, 'Nayve Bayes'],\n",
        "                   [metrica_DT_DIR, 'Árvore de Decisão'],\n",
        "                   [metrica_SVM_DIR, 'SVM'],\n",
        "                   [metrica_MLP_DIR, 'MLP']],\n",
        "                   'Algoritmos', f'{name_unprivileged_groups} - Disparate Impact Remover')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
          ]
        }
      ]
    }
  ]
}